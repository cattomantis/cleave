{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nasheedyasin/miniconda3/envs/expts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", use_safetensors=True, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nasheedyasin/Documents/GitHub/cleave/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 04 Mar 2025\n",
      "\n",
      "You are a pirate chatbot who always responds in pirate speak!user\n",
      "\n",
      "Who are you?assistant\n",
      "\n",
      "MeAhWelcomeWelcomeYeYipel datipel mai YerGreetings capableAArrNorA-aAAAAAA-thanA'eriverse-than soloificant soloSet-thanantedSoSnŠDbSe sailedPlipelSeSeDBorsHiHianted sniffipel Ragnarors sniffipel portsipel conversions sane conversionSwiants Standards conversion sniff sniff sniffDBiorabilityDb sniff conversionsipel conversion conversionabilityipelizationizationabilityonorSeaven tongues lingonsense Ragnar translationsiorBay translationBay language swearTechn TranslationEnglishursonor ling invented Norse translationConversionTechn never tonguesoranConversion Davaven Standards standards language� swear Dav language language Never never equivalentsib invented conversion Still invented Translationoran supported Danish langgons language language invented never fought fought conversiongons never Norse language Never equivalentsNever conversionib languagegons Hag invented swear translation Translation swear Translation negotiated banners translated technically fought Standard supported Never languages never Never negotiated swear Conduct Dee standards language Standard never Store national Deenets language national bannersook standards supported SVN technically never ภาษnets national Store Standards translatedoran Conductour standards Sharks sweargonsNever Sharks Storenets ourselves national Still Standards negotiated accepted Standard technicallyengan supported never language foreigners conversion conversion Gael technically swear national Neverour conna technicallyducted nationalleadibel fought fought technically Store Sharks Standards standards SVNunsupportedoran swear connalead foreigners technically Hogan never Never standards supportedTechn Standardlead swear sniff Store Storeour sniff Standards?\"oran language Standardsoran flags Standards technicallygonsNever never ourselves invented?\"std herself Sharks Standardsunsupported national banners standards technicallyook Neverductedems supported Nation?\" nationalgons technically ourselves national Store Nation Standard Never दस Standards supportedouremsook ConductTechn never never herself swear Standards swear swear Store Never Sharks standards Never Standards swear technicallyducted Standards Standards Standards technically sniff Conduct conductTechn Never flags Standards Nation Never Never Never HoganTechn national national standards Never standards Standards([[nets sniff never Standardunsupported standards Sharks invented standards never Testibelnets supported technically never Standardslead technicallyNeverook Techn Never Never invented StandardsNever Never Standards never Standards conduct personal standards Sharks conna TechnStorestdBay standards([[ ourselves neverNever themselves ourselvesNever Sharks Standards standards banners sniffnetsNeverNever supported inventedook personal banners standards never nationalnetsNever conna Standardsook technically Standards ourselves Nation Standards Standards Store([[Neverlead?\" standards Never swear flagsgonsTechn sniff never supported Standardsducted conduct conduct Never themselves Standards Standards Never Test Bay standards conna Deb supported ourselves Bay standards Neverductedlead conna Standards standardsgons standardsgonsnets standards Standards standardsook Standards herself([[ standards personal never Store supported SharksTechn Sharks herself Deb?\n",
      "\n",
      "ems Standards standards Store invented NeverNever StorenetsNever Standards?\n",
      "\n",
      " herself herselfTechnleadlead herself?\" Standard personal herselfunsupportedlead\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "from cleave.monkeypatches import latent_prepare_inputs_for_generation, latent_sample\n",
    "\n",
    "# patch model\n",
    "model.__class__ = type(\"AutoModelForCausalLatentLM\", (model.__class__,), {\n",
    "    \"_sample\": latent_sample,\n",
    "    \"prepare_inputs_for_generation\": latent_prepare_inputs_for_generation\n",
    "})\n",
    "\n",
    "prompt = \"Who are you?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "batch_text = tokenizer.apply_chat_template(\n",
    "    [messages],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "\n",
    "inputs = tokenizer(batch_text, return_tensors=\"pt\").to(model.device)\n",
    "pad_token_id = model.config.eos_token_id if isinstance(model.config.eos_token_id, int) else model.config.eos_token_id[0]\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=512,\n",
    "    pad_token_id=pad_token_id, do_sample=True\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
